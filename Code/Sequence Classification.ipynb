{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, RepeatVector, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data_60_points.csv\")\n",
    "final_df = pd.read_csv(\"real_trainable_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>471</th>\n",
       "      <th>472</th>\n",
       "      <th>473</th>\n",
       "      <th>474</th>\n",
       "      <th>475</th>\n",
       "      <th>476</th>\n",
       "      <th>477</th>\n",
       "      <th>478</th>\n",
       "      <th>479</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.292663</td>\n",
       "      <td>19.482136</td>\n",
       "      <td>8.624346</td>\n",
       "      <td>-0.932498</td>\n",
       "      <td>-0.395269</td>\n",
       "      <td>-0.455120</td>\n",
       "      <td>0.855522</td>\n",
       "      <td>0.265530</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.375534</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.311551</td>\n",
       "      <td>-22.457486</td>\n",
       "      <td>-28.753222</td>\n",
       "      <td>-27.479641</td>\n",
       "      <td>-28.066095</td>\n",
       "      <td>-25.329087</td>\n",
       "      <td>-24.605612</td>\n",
       "      <td>-24.266738</td>\n",
       "      <td>-21.633146</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.989555</td>\n",
       "      <td>10.538844</td>\n",
       "      <td>4.357757</td>\n",
       "      <td>-4.671976</td>\n",
       "      <td>-2.448575</td>\n",
       "      <td>-0.195571</td>\n",
       "      <td>0.800786</td>\n",
       "      <td>3.143261</td>\n",
       "      <td>5.239468</td>\n",
       "      <td>4.201113</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.004589</td>\n",
       "      <td>-22.251523</td>\n",
       "      <td>-24.471177</td>\n",
       "      <td>-27.359055</td>\n",
       "      <td>-32.696794</td>\n",
       "      <td>-36.146539</td>\n",
       "      <td>-31.180339</td>\n",
       "      <td>-26.265950</td>\n",
       "      <td>-24.452572</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.226338</td>\n",
       "      <td>22.926922</td>\n",
       "      <td>12.568386</td>\n",
       "      <td>5.334923</td>\n",
       "      <td>5.037145</td>\n",
       "      <td>4.942274</td>\n",
       "      <td>5.231862</td>\n",
       "      <td>5.857457</td>\n",
       "      <td>4.706730</td>\n",
       "      <td>3.209744</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.205840</td>\n",
       "      <td>-26.171166</td>\n",
       "      <td>-28.149451</td>\n",
       "      <td>-30.068256</td>\n",
       "      <td>-28.035475</td>\n",
       "      <td>-23.902512</td>\n",
       "      <td>-21.659425</td>\n",
       "      <td>-22.133117</td>\n",
       "      <td>-22.457960</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.275999</td>\n",
       "      <td>4.947967</td>\n",
       "      <td>-2.816720</td>\n",
       "      <td>-0.592784</td>\n",
       "      <td>3.641866</td>\n",
       "      <td>4.649932</td>\n",
       "      <td>2.646541</td>\n",
       "      <td>-1.270290</td>\n",
       "      <td>-2.929141</td>\n",
       "      <td>-6.799285</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.478831</td>\n",
       "      <td>-25.957031</td>\n",
       "      <td>-28.022580</td>\n",
       "      <td>-31.121322</td>\n",
       "      <td>-33.086501</td>\n",
       "      <td>-26.612358</td>\n",
       "      <td>-23.061996</td>\n",
       "      <td>-22.466169</td>\n",
       "      <td>-24.421495</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.701159</td>\n",
       "      <td>19.995006</td>\n",
       "      <td>9.928850</td>\n",
       "      <td>2.699057</td>\n",
       "      <td>3.008508</td>\n",
       "      <td>3.815365</td>\n",
       "      <td>4.283556</td>\n",
       "      <td>5.071418</td>\n",
       "      <td>6.786370</td>\n",
       "      <td>5.908505</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.841160</td>\n",
       "      <td>-16.545065</td>\n",
       "      <td>-18.070230</td>\n",
       "      <td>-22.589697</td>\n",
       "      <td>-27.299603</td>\n",
       "      <td>-27.420140</td>\n",
       "      <td>-24.701882</td>\n",
       "      <td>-23.104943</td>\n",
       "      <td>-23.844575</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 481 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2         3         4         5         6  \\\n",
       "0  24.292663  19.482136   8.624346 -0.932498 -0.395269 -0.455120  0.855522   \n",
       "1  13.989555  10.538844   4.357757 -4.671976 -2.448575 -0.195571  0.800786   \n",
       "2  28.226338  22.926922  12.568386  5.334923  5.037145  4.942274  5.231862   \n",
       "3  10.275999   4.947967  -2.816720 -0.592784  3.641866  4.649932  2.646541   \n",
       "4  25.701159  19.995006   9.928850  2.699057  3.008508  3.815365  4.283556   \n",
       "\n",
       "          7         8         9  ...        471        472        473  \\\n",
       "0  0.265530  0.903650  0.375534  ... -17.311551 -22.457486 -28.753222   \n",
       "1  3.143261  5.239468  4.201113  ... -17.004589 -22.251523 -24.471177   \n",
       "2  5.857457  4.706730  3.209744  ... -23.205840 -26.171166 -28.149451   \n",
       "3 -1.270290 -2.929141 -6.799285  ... -23.478831 -25.957031 -28.022580   \n",
       "4  5.071418  6.786370  5.908505  ... -16.841160 -16.545065 -18.070230   \n",
       "\n",
       "         474        475        476        477        478        479  Target  \n",
       "0 -27.479641 -28.066095 -25.329087 -24.605612 -24.266738 -21.633146     1.0  \n",
       "1 -27.359055 -32.696794 -36.146539 -31.180339 -26.265950 -24.452572     2.0  \n",
       "2 -30.068256 -28.035475 -23.902512 -21.659425 -22.133117 -22.457960     3.0  \n",
       "3 -31.121322 -33.086501 -26.612358 -23.061996 -22.466169 -24.421495     4.0  \n",
       "4 -22.589697 -27.299603 -27.420140 -24.701882 -23.104943 -23.844575     5.0  \n",
       "\n",
       "[5 rows x 481 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = final_df.drop(\"Target\", axis = 1)\n",
    "targets = final_df.Target \n",
    "targets = targets.apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Own Train and Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20808, 480), (20808,), (3672, 480), (3672,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.15, random_state=42)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization and Standarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# configure our pipeline\n",
    "pipeline = Pipeline([('normalizer', Normalizer()),\n",
    "                     ('scaler', MinMaxScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline.fit(x_train)\n",
    "\n",
    "#x_train = pipeline.transform(x_train)\n",
    "#x_test = pipeline.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Subsequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsequence for each 60 timestep (each a different channel)\n",
    "\n",
    "def create_subsequences(x,timestep = 1):\n",
    "    Xs = []\n",
    "    stop_index = ((len(x)-timestep))\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        if(i<=stop_index):\n",
    "            Xs.append(x.iloc[i:(i+timestep),:])\n",
    "        else:\n",
    "            #same_array = [x[i,:]]*10\n",
    "            Xs.append(x.iloc[(i-timestep):i,:])\n",
    "    return np.array(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = create_subsequences(x_train)\n",
    "x_test = create_subsequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20808, 1, 480), (3672, 1, 480), (20808,), (3672,))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_40 (LSTM)              (None, 1, 128)            311808    \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 1, 128)            0         \n",
      "                                                                 \n",
      " lstm_41 (LSTM)              (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " repeat_vector_10 (RepeatVec  (None, 1, 64)            0         \n",
      " tor)                                                            \n",
      "                                                                 \n",
      " lstm_42 (LSTM)              (None, 1, 64)             33024     \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 1, 64)             0         \n",
      "                                                                 \n",
      " lstm_43 (LSTM)              (None, 1, 128)            98816     \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 1, 128)            0         \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, 1, 12)            1548      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 494,604\n",
      "Trainable params: 494,604\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "timesteps = x_train.shape[1]\n",
    "nfeatures = x_train.shape[2]\n",
    "input_shape = (timesteps,nfeatures)\n",
    "\n",
    "outputs = len(y_train.unique())\n",
    "\n",
    "model.add(LSTM(128, activation = 'relu', return_sequences=True, input_shape = input_shape))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(RepeatVector(timesteps))\n",
    "model.add(LSTM(64, activation = 'relu',return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, activation = 'relu',return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(TimeDistributed(Dense(outputs, activation=\"softmax\")))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 1, 12) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alexc\\OneDrive\\Documents\\Taiwan Classes\\Second Semester\\Brain Computer Interfaces\\BCI Presentation and Project\\SSVEP Projects\\Wearable SSVEP BCI Database\\SSVEP-BCI-Project\\Code\\Sequence Classification.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alexc/OneDrive/Documents/Taiwan%20Classes/Second%20Semester/Brain%20Computer%20Interfaces/BCI%20Presentation%20and%20Project/SSVEP%20Projects/Wearable%20SSVEP%20BCI%20Database/SSVEP-BCI-Project/Code/Sequence%20Classification.ipynb#ch0000134?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alexc/OneDrive/Documents/Taiwan%20Classes/Second%20Semester/Brain%20Computer%20Interfaces/BCI%20Presentation%20and%20Project/SSVEP%20Projects/Wearable%20SSVEP%20BCI%20Database/SSVEP-BCI-Project/Code/Sequence%20Classification.ipynb#ch0000134?line=5'>6</a>\u001b[0m early_stop \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m,min_delta\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m,patience\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m,restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/alexc/OneDrive/Documents/Taiwan%20Classes/Second%20Semester/Brain%20Computer%20Interfaces/BCI%20Presentation%20and%20Project/SSVEP%20Projects/Wearable%20SSVEP%20BCI%20Database/SSVEP-BCI-Project/Code/Sequence%20Classification.ipynb#ch0000134?line=7'>8</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(x_test, y_test),verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[early_stop])\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/alexc/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/alexc/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/alexc/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/alexc/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/alexc/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/alexc/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1144'>1145</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/alexc/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1145'>1146</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> <a href='file:///c%3A/Users/alexc/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1146'>1147</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   <a href='file:///c%3A/Users/alexc/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1147'>1148</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/alexc/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1148'>1149</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\alexc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 1, 12) are incompatible\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "#model.compile(loss='mse', optimizer=adam, metrics=[\"acc\"])\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',min_delta=0.0001,patience=3,verbose=1, mode='min',restore_best_weights=True)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=15, validation_data=(x_test, y_test),verbose=2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32a797c5569203baa308ccdf935e7b699fe5a2ef5e18bd6e0a3aea8e28291ff8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
